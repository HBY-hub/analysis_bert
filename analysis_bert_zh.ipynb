{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "analysis_bert_zh.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "pytorch",
   "language": "python",
   "display_name": "pytorch"
  },
  "accelerator": "GPU",
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "fd266bbd0e12414d92244044ef427378": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_e6e1a311f6bc4b568a0922ba8af26df2",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_425e5cef26b74f7ba38c723aff09dca3",
       "IPY_MODEL_5d4a3316a4ae4b80993a7e78000da8af"
      ]
     }
    },
    "e6e1a311f6bc4b568a0922ba8af26df2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "425e5cef26b74f7ba38c723aff09dca3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_13990397e9a74157a0d8e5410c710352",
      "_dom_classes": [],
      "description": "Downloading: 100%",
      "_model_name": "FloatProgressModel",
      "bar_style": "success",
      "max": 624,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 624,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_d0bf3e660f174cad95ec6b9903f387d6"
     }
    },
    "5d4a3316a4ae4b80993a7e78000da8af": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_26f2eb200a5f446ba8f582019325b4e2",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 624/624 [00:00&lt;00:00, 923B/s]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_931267e3fff547fb8c992d5bf431ec85"
     }
    },
    "13990397e9a74157a0d8e5410c710352": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "initial",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "d0bf3e660f174cad95ec6b9903f387d6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "26f2eb200a5f446ba8f582019325b4e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "931267e3fff547fb8c992d5bf431ec85": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "a78d7c96c1fb43eb9f83be5ee9931aa1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_974d37e88fd543409fcc1d4ef1dc5100",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_d090f9c909a943fc9b4fe7fd72014b0f",
       "IPY_MODEL_e88f5826e0ed4173bfc677b71b1a9f15"
      ]
     }
    },
    "974d37e88fd543409fcc1d4ef1dc5100": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "d090f9c909a943fc9b4fe7fd72014b0f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_a08fffb10276421baf3498cb1c919186",
      "_dom_classes": [],
      "description": "Downloading: 100%",
      "_model_name": "FloatProgressModel",
      "bar_style": "success",
      "max": 411577189,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 411577189,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_bb9543d3be5c4ad5bd627245c2fa3664"
     }
    },
    "e88f5826e0ed4173bfc677b71b1a9f15": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_d3506becee294710bf44f7ced290d3e6",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 412M/412M [00:09&lt;00:00, 43.8MB/s]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_45d081d4b25b45aeb1fa00b713701184"
     }
    },
    "a08fffb10276421baf3498cb1c919186": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "initial",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "bb9543d3be5c4ad5bd627245c2fa3664": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "d3506becee294710bf44f7ced290d3e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "45d081d4b25b45aeb1fa00b713701184": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "U30tul4YDmno",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 372
    },
    "outputId": "2ef73a0a-b96f-4a50-f3ab-6940f164f1e5"
   },
   "source": [
    "# 看一看用的什么显卡\n",
    "!nvidia-smi"
   ],
   "execution_count": 18,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Wed Sep  2 00:23:09 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.66       Driver Version: 418.67       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   33C    P8     7W /  75W |      0MiB /  7611MiB |      0%      Default |\n",
      "|                               |                      |                 ERR! |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "oQgXyYO2Dvcu",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "!pip install transformers\n",
    "!unzip /content/drive/Shared\\ drives/hbyscgsg@gmail.com/weibo_senti_100k.zip"
   ],
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "EugO-_A-EMVf",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "import torch \n",
    "import pandas as pd"
   ],
   "execution_count": 20,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "yEPz46ZQERMx",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 687
    },
    "outputId": "7c6c97fe-a63d-41f6-9640-c8d67c705779"
   },
   "source": [
    "pd_all = pd.read_csv(\"/content/weibo_senti_100k.csv\")\n",
    "print('评论数目（总体）：%d' % pd_all.shape[0])\n",
    "print('评论数目（正向）：%d' % pd_all[pd_all.label==1].shape[0])\n",
    "print('评论数目（负向）：%d' % pd_all[pd_all.label==0].shape[0])\n",
    "pd_all.sample(20)"
   ],
   "execution_count": 22,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "评论数目（总体）：119988\n",
      "评论数目（正向）：59993\n",
      "评论数目（负向）：59995\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7581</th>\n",
       "      <td>1</td>\n",
       "      <td>欢迎常来哈!![鼓掌] //@江山映像:给自己加加钢:中午和同事溜达到此，本想补补气，甩去这...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19558</th>\n",
       "      <td>1</td>\n",
       "      <td>幸福可以像花儿一样~~办公室的惊喜~~谢谢~~[爱你]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57935</th>\n",
       "      <td>1</td>\n",
       "      <td>[亲亲]参加《优品》活动的演出照片，《优品》杂志只推介高大上，宣称“君子爱奢，侈之有道”的理...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9456</th>\n",
       "      <td>1</td>\n",
       "      <td>兰亭序~王羲之童鞋的啦~[嘻嘻] //@国安密码:高大上的节奏，看不懂啊</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114251</th>\n",
       "      <td>0</td>\n",
       "      <td>当你行走他乡的时候，有木有一个导游在唾沫横飞的乱侃着当地香艳的传说故事？抑或是阴森着讲述那不...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36033</th>\n",
       "      <td>1</td>\n",
       "      <td>自从有了微信，每个月的短信基本为零。现在微信也可以视频了。像我这样整天足不出户的宅亲有了和世...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81278</th>\n",
       "      <td>0</td>\n",
       "      <td>原味酸奶，酸......[泪]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83393</th>\n",
       "      <td>0</td>\n",
       "      <td>wow~帝都的四惠地铁站还是小了点,今儿算是感受到人潮如织的意义啦[汗]检票口到站台拐来拐去...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116864</th>\n",
       "      <td>0</td>\n",
       "      <td>[泪]哇，真的是第一个~~谢谢樱桃钗小姑凉~~当当当！</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86386</th>\n",
       "      <td>0</td>\n",
       "      <td>感觉我跟周伯通似的，左右互搏啊。。。。[泪]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105679</th>\n",
       "      <td>0</td>\n",
       "      <td>据说你流出来的眼泪是你脑子里进的水。。。[泪]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65040</th>\n",
       "      <td>0</td>\n",
       "      <td>我发誓，我真有杀死这群畜生的冲动[怒]  法律对这群人渣来说没用//@紫陌红尘SKY:摔死他...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35003</th>\n",
       "      <td>1</td>\n",
       "      <td>撞色啦！[哈哈][哈哈][哈哈] 我在:http://t.cn/zYiLYlr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25183</th>\n",
       "      <td>1</td>\n",
       "      <td>阔别14天,终于回到我爱的直播台.直播签到贴,快来说说你的晚餐吃什么?[太开心][太开心][...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47854</th>\n",
       "      <td>1</td>\n",
       "      <td>各位小伙伴们 明信片已寄出 请记得查看自家信箱[嘻嘻]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100036</th>\n",
       "      <td>0</td>\n",
       "      <td>回复@靖添尧:俺家员工没有退役潜水员！[泪] //@靖添尧:为你的员工负责，必须米有~ //...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75310</th>\n",
       "      <td>0</td>\n",
       "      <td>@米勒嘟嘟 @Catherine__ZENG 那些年我们一步步量过的地方[泪][泪] //@...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115371</th>\n",
       "      <td>0</td>\n",
       "      <td>//@好狗好猫义工团上海站: 领养代替购买的没有买卖没有伤害[泪]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119330</th>\n",
       "      <td>0</td>\n",
       "      <td>我是惯犯了，罪不可赦呀 //@维C雪儿:#五一假期#悲催的我，正在犯法中。。。[泪] //@...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119552</th>\n",
       "      <td>0</td>\n",
       "      <td>//@窝窝头的围脖: 西安，俺的第二故乡。思长安，心戚戚[泪]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        label                                             review\n",
       "7581        1  欢迎常来哈!![鼓掌] //@江山映像:给自己加加钢:中午和同事溜达到此，本想补补气，甩去这...\n",
       "19558       1                        幸福可以像花儿一样~~办公室的惊喜~~谢谢~~[爱你]\n",
       "57935       1  [亲亲]参加《优品》活动的演出照片，《优品》杂志只推介高大上，宣称“君子爱奢，侈之有道”的理...\n",
       "9456        1               兰亭序~王羲之童鞋的啦~[嘻嘻] //@国安密码:高大上的节奏，看不懂啊\n",
       "114251      0  当你行走他乡的时候，有木有一个导游在唾沫横飞的乱侃着当地香艳的传说故事？抑或是阴森着讲述那不...\n",
       "36033       1  自从有了微信，每个月的短信基本为零。现在微信也可以视频了。像我这样整天足不出户的宅亲有了和世...\n",
       "81278       0                                    原味酸奶，酸......[泪]\n",
       "83393       0  wow~帝都的四惠地铁站还是小了点,今儿算是感受到人潮如织的意义啦[汗]检票口到站台拐来拐去...\n",
       "116864      0                        [泪]哇，真的是第一个~~谢谢樱桃钗小姑凉~~当当当！\n",
       "86386       0                             感觉我跟周伯通似的，左右互搏啊。。。。[泪]\n",
       "105679      0                            据说你流出来的眼泪是你脑子里进的水。。。[泪]\n",
       "65040       0  我发誓，我真有杀死这群畜生的冲动[怒]  法律对这群人渣来说没用//@紫陌红尘SKY:摔死他...\n",
       "35003       1            撞色啦！[哈哈][哈哈][哈哈] 我在:http://t.cn/zYiLYlr\n",
       "25183       1  阔别14天,终于回到我爱的直播台.直播签到贴,快来说说你的晚餐吃什么?[太开心][太开心][...\n",
       "47854       1                        各位小伙伴们 明信片已寄出 请记得查看自家信箱[嘻嘻]\n",
       "100036      0  回复@靖添尧:俺家员工没有退役潜水员！[泪] //@靖添尧:为你的员工负责，必须米有~ //...\n",
       "75310       0  @米勒嘟嘟 @Catherine__ZENG 那些年我们一步步量过的地方[泪][泪] //@...\n",
       "115371      0                  //@好狗好猫义工团上海站: 领养代替购买的没有买卖没有伤害[泪]\n",
       "119330      0  我是惯犯了，罪不可赦呀 //@维C雪儿:#五一假期#悲催的我，正在犯法中。。。[泪] //@...\n",
       "119552      0                    //@窝窝头的围脖: 西安，俺的第二故乡。思长安，心戚戚[泪]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 22
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "C4IoiT05KpWG",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "train_size = int(0.8 * 119988)\n",
    "test_size = 119988 - train_size\n",
    "train_indices,test_indices = torch.utils.data.random_split(pd_all,[train_size,test_size])"
   ],
   "execution_count": 2,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-2-5221c4fce9dc>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[0mtrain_size\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m0.8\u001B[0m \u001B[1;33m*\u001B[0m \u001B[1;36m119988\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[0mtest_size\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m119988\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0mtrain_size\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m \u001B[0mtrain_indices\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mtest_indices\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mutils\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrandom_split\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpd_all\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mtrain_size\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mtest_size\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      4\u001B[0m \u001B[0mtrain_size\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'torch' is not defined"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "AiMCdh9uT4Ms",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "sentences = pd_all['review']\n",
    "labels = pd_all['label']"
   ],
   "execution_count": 99,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "hkze4riQIChd",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "train_labels=[]\n",
    "for i in train_indices.indices:\n",
    "  train_labels.append(labels[i])\n",
    "\n",
    "train_sentences=[]\n",
    "for i in train_indices.indices:\n",
    "  train_sentences.append(sentences[i])\n",
    "\n",
    "test_labels=[]\n",
    "for i in test_indices.indices:\n",
    "  test_labels.append(labels[i])\n",
    "\n",
    "test_sentences=[]\n",
    "for i in test_indices.indices:\n",
    "  test_sentences.append(sentences[i])"
   ],
   "execution_count": 125,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "sAf3G-gsXGIt",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "outputId": "874030da-7b93-4b8f-fdbf-b577bfc95be8"
   },
   "source": [
    "len(train_labels)"
   ],
   "execution_count": 123,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "95990"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 123
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "0l6e-79gGhPR",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "from transformers import BertTokenizer\n",
    "bert_model = \"bert-base-chinese\"\n",
    "tokenizer = BertTokenizer.from_pretrained(bert_model)"
   ],
   "execution_count": 116,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "c3j0nZv-JXTy",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "outputId": "d20ecf3d-41bf-4a71-c17f-965197d56788"
   },
   "source": [
    "# Print the original sentence.\n",
    "print(' Original: ', train_sentences[1])\n",
    "\n",
    "# Print the sentence split into tokens.\n",
    "print('Tokenized: ', tokenizer.tokenize(train_sentences[1]))\n",
    "\n",
    "# Print the sentence mapped to token ids.\n",
    "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(train_sentences[1])))"
   ],
   "execution_count": 106,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      " Original:  #年夜饭# 国贸饭店东方餐厅推出三款不同价位的年夜饭，特别推荐[good]【雪菜明虾球】【曲靖风味大排】【菌菇汁牛柳】，邀您与家人一起来品尝这些美味佳肴！[围观][太开心]\n",
      "Tokenized:  ['#', '年', '夜', '饭', '#', '国', '贸', '饭', '店', '东', '方', '餐', '厅', '推', '出', '三', '款', '不', '同', '价', '位', '的', '年', '夜', '饭', '，', '特', '别', '推', '荐', '[', 'good', ']', '【', '雪', '菜', '明', '虾', '球', '】', '【', '曲', '靖', '风', '味', '大', '排', '】', '【', '菌', '菇', '汁', '牛', '柳', '】', '，', '邀', '您', '与', '家', '人', '一', '起', '来', '品', '尝', '这', '些', '美', '味', '佳', '肴', '！', '[', '围', '观', ']', '[', '太', '开', '心', ']']\n",
      "Token IDs:  [108, 2399, 1915, 7649, 108, 1744, 6588, 7649, 2421, 691, 3175, 7623, 1324, 2972, 1139, 676, 3621, 679, 1398, 817, 855, 4638, 2399, 1915, 7649, 8024, 4294, 1166, 2972, 5773, 138, 9005, 140, 523, 7434, 5831, 3209, 6007, 4413, 524, 523, 3289, 7473, 7599, 1456, 1920, 2961, 524, 523, 5826, 5823, 3723, 4281, 3394, 524, 8024, 6913, 2644, 680, 2157, 782, 671, 6629, 3341, 1501, 2214, 6821, 763, 5401, 1456, 881, 5510, 8013, 138, 1741, 6225, 140, 138, 1922, 2458, 2552, 140]\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "R-YtJMlCJsEg",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "outputId": "56bd1af3-d924-4fd7-adbf-09540d094863"
   },
   "source": [
    "MAX_LEN=128\n",
    "\n",
    "input_ids = [tokenizer.encode(sent,add_special_tokens=True,max_length=MAX_LEN,truncation=True) for sent in train_sentences]\n",
    "test_input_ids = [tokenizer.encode(sent,add_special_tokens=True,max_length=MAX_LEN,truncation=True) for sent in test_sentences]\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
    "\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", \n",
    "                          value=0, truncating=\"post\", padding=\"post\")\n",
    "test_input_ids = pad_sequences(test_input_ids, maxlen=MAX_LEN, dtype=\"long\", \n",
    "                          value=0, truncating=\"post\", padding=\"post\")\n",
    "print(\"finish\")"
   ],
   "execution_count": 117,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "\n",
      "Padding token: \"[PAD]\", ID: 0\n",
      "finish\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "goVTniO1MLMn",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    " # Create attention masks\n",
    "attention_masks = []\n",
    "\n",
    "# For each sentence...\n",
    "for sent in input_ids:\n",
    "    \n",
    "    # Create the attention mask.\n",
    "    #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
    "    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
    "    att_mask = [int(token_id > 0) for token_id in sent]\n",
    "    \n",
    "    # Store the attention mask for this sentence.\n",
    "    attention_masks.append(att_mask)\n",
    "\n",
    "    \n",
    "test_attention_masks = []\n",
    "\n",
    "# For each sentence...\n",
    "for sent in test_input_ids:\n",
    "    att_mask = [int(token_id > 0) for token_id in sent]\n",
    "    test_attention_masks.append(att_mask)\n"
   ],
   "execution_count": 119,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "jchFAt9AMOb_",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "labels = train_labels\n",
    "# Use 90% for training and 10% for validation.\n",
    "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n",
    "                                                            random_state=2020, test_size=0.1)\n",
    "# Do the same for the masks.\n",
    "train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels,\n",
    "                                             random_state=2020, test_size=0.1)"
   ],
   "execution_count": 126,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "UZEnMJ9NMhox",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "outputId": "cb13c663-6e79-49da-d35c-69cc9f246a99"
   },
   "source": [
    "import torch\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "test_inputs=torch.tensor(test_input_ids)\n",
    "\n",
    "train_labels = torch.tensor(train_labels)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "test_labels=torch.tensor(test_labels)\n",
    "\n",
    "train_masks = torch.tensor(train_masks)\n",
    "validation_masks = torch.tensor(validation_masks)\n",
    "test_masks=torch.tensor(test_attention_masks)\n",
    "\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# The DataLoader needs to know our batch size for training, so we specify it \n",
    "# here.\n",
    "# For fine-tuning BERT on a specific task, the authors recommend a batch size of\n",
    "# 16 or 32.\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "# Create the DataLoader for our training set.\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# Create the DataLoader for our validation set.\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n",
    "\n",
    "# Create the DataLoader for our test set.\n",
    "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
    "test_sampler = SequentialSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
   ],
   "execution_count": 133,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ],
     "name": "stderr"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "yr0xxFmuMr3v",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "fd266bbd0e12414d92244044ef427378",
      "e6e1a311f6bc4b568a0922ba8af26df2",
      "425e5cef26b74f7ba38c723aff09dca3",
      "5d4a3316a4ae4b80993a7e78000da8af",
      "13990397e9a74157a0d8e5410c710352",
      "d0bf3e660f174cad95ec6b9903f387d6",
      "26f2eb200a5f446ba8f582019325b4e2",
      "931267e3fff547fb8c992d5bf431ec85",
      "a78d7c96c1fb43eb9f83be5ee9931aa1",
      "974d37e88fd543409fcc1d4ef1dc5100",
      "d090f9c909a943fc9b4fe7fd72014b0f",
      "e88f5826e0ed4173bfc677b71b1a9f15",
      "a08fffb10276421baf3498cb1c919186",
      "bb9543d3be5c4ad5bd627245c2fa3664",
      "d3506becee294710bf44f7ced290d3e6",
      "45d081d4b25b45aeb1fa00b713701184"
     ]
    },
    "outputId": "b5d52248-5b21-40d4-8a52-acf4b6b6730a"
   },
   "source": [
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "\n",
    "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
    "# linear classification layer on top. \n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-chinese\", # Use the 12-layer BERT model, with an uncased vocab.\n",
    "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
    "                    # You can increase this for multi-class tasks.   \n",
    "    output_attentions = False, # Whether the model returns attentions weights.\n",
    "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    ")\n",
    "\n",
    "# Tell pytorch to run this model on the GPU.\n",
    "model.cuda()"
   ],
   "execution_count": 128,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd266bbd0e12414d92244044ef427378",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=624.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {
      "tags": []
     }
    },
    {
     "output_type": "stream",
     "text": [
      "\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a78d7c96c1fb43eb9f83be5ee9931aa1",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=411577189.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {
      "tags": []
     }
    },
    {
     "output_type": "stream",
     "text": [
      "\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-chinese and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 128
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "eHoBwzoCMySH",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "                )\n",
    "\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# Number of training epochs (authors recommend between 2 and 4)\n",
    "epochs = 2\n",
    "\n",
    "# Total number of training steps is number of batches * number of epochs.\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)"
   ],
   "execution_count": 129,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6R-DEB70M0sH",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ],
   "execution_count": 130,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "YAM8m2XeM4XX",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "outputId": "a6ca579a-2fde-425d-a49c-92560bc78eeb"
   },
   "source": [
    "import random\n",
    "\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Store the average loss after each epoch so we can plot them.\n",
    "loss_values = []\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, 1):# epoches\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    \n",
    "    # Perform one full pass over the training set.\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_loss = 0\n",
    "    model.train()\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        model.zero_grad()        \n",
    "        outputs = model(b_input_ids, \n",
    "                    token_type_ids=None, \n",
    "                    attention_mask=b_input_mask, \n",
    "                    labels=b_labels)\n",
    "        \n",
    "        # The call to `model` always returns a tuple, so we need to pull the \n",
    "        # loss value out of the tuple.\n",
    "        loss = outputs[0]\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over the training data.\n",
    "    avg_train_loss = total_loss / len(train_dataloader)            \n",
    "    \n",
    "    # Store the loss value for plotting the learning curve.\n",
    "    loss_values.append(avg_train_loss)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
    "        \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        # Add batch to GPU\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        with torch.no_grad():        \n",
    "            outputs = model(b_input_ids, \n",
    "                            token_type_ids=None, \n",
    "                            attention_mask=b_input_mask)\n",
    "        \n",
    "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
    "        # values prior to applying an activation function like the softmax.\n",
    "        logits = outputs[0]\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        \n",
    "        # Calculate the accuracy for this batch of test sentences.\n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "        \n",
    "        # Accumulate the total accuracy.\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "\n",
    "        # Track the number of batches\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
    "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")"
   ],
   "execution_count": 132,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 2 ========\n",
      "Training...\n",
      "  Batch    40  of  5,400.    Elapsed: 0:00:17.\n",
      "  Batch    80  of  5,400.    Elapsed: 0:00:34.\n",
      "  Batch   120  of  5,400.    Elapsed: 0:00:51.\n",
      "  Batch   160  of  5,400.    Elapsed: 0:01:08.\n",
      "  Batch   200  of  5,400.    Elapsed: 0:01:25.\n",
      "  Batch   240  of  5,400.    Elapsed: 0:01:42.\n",
      "  Batch   280  of  5,400.    Elapsed: 0:01:59.\n",
      "  Batch   320  of  5,400.    Elapsed: 0:02:17.\n",
      "  Batch   360  of  5,400.    Elapsed: 0:02:34.\n",
      "  Batch   400  of  5,400.    Elapsed: 0:02:51.\n",
      "  Batch   440  of  5,400.    Elapsed: 0:03:08.\n",
      "  Batch   480  of  5,400.    Elapsed: 0:03:26.\n",
      "  Batch   520  of  5,400.    Elapsed: 0:03:43.\n",
      "  Batch   560  of  5,400.    Elapsed: 0:04:00.\n",
      "  Batch   600  of  5,400.    Elapsed: 0:04:18.\n",
      "  Batch   640  of  5,400.    Elapsed: 0:04:35.\n",
      "  Batch   680  of  5,400.    Elapsed: 0:04:52.\n",
      "  Batch   720  of  5,400.    Elapsed: 0:05:09.\n",
      "  Batch   760  of  5,400.    Elapsed: 0:05:27.\n",
      "  Batch   800  of  5,400.    Elapsed: 0:05:44.\n",
      "  Batch   840  of  5,400.    Elapsed: 0:06:01.\n",
      "  Batch   880  of  5,400.    Elapsed: 0:06:19.\n",
      "  Batch   920  of  5,400.    Elapsed: 0:06:36.\n",
      "  Batch   960  of  5,400.    Elapsed: 0:06:53.\n",
      "  Batch 1,000  of  5,400.    Elapsed: 0:07:10.\n",
      "  Batch 1,040  of  5,400.    Elapsed: 0:07:28.\n",
      "  Batch 1,080  of  5,400.    Elapsed: 0:07:45.\n",
      "  Batch 1,120  of  5,400.    Elapsed: 0:08:02.\n",
      "  Batch 1,160  of  5,400.    Elapsed: 0:08:20.\n",
      "  Batch 1,200  of  5,400.    Elapsed: 0:08:37.\n",
      "  Batch 1,240  of  5,400.    Elapsed: 0:08:55.\n",
      "  Batch 1,280  of  5,400.    Elapsed: 0:09:12.\n",
      "  Batch 1,320  of  5,400.    Elapsed: 0:09:29.\n",
      "  Batch 1,360  of  5,400.    Elapsed: 0:09:47.\n",
      "  Batch 1,400  of  5,400.    Elapsed: 0:10:04.\n",
      "  Batch 1,440  of  5,400.    Elapsed: 0:10:21.\n",
      "  Batch 1,480  of  5,400.    Elapsed: 0:10:38.\n",
      "  Batch 1,520  of  5,400.    Elapsed: 0:10:56.\n",
      "  Batch 1,560  of  5,400.    Elapsed: 0:11:13.\n",
      "  Batch 1,600  of  5,400.    Elapsed: 0:11:30.\n",
      "  Batch 1,640  of  5,400.    Elapsed: 0:11:48.\n",
      "  Batch 1,680  of  5,400.    Elapsed: 0:12:05.\n",
      "  Batch 1,720  of  5,400.    Elapsed: 0:12:22.\n",
      "  Batch 1,760  of  5,400.    Elapsed: 0:12:40.\n",
      "  Batch 1,800  of  5,400.    Elapsed: 0:12:57.\n",
      "  Batch 1,840  of  5,400.    Elapsed: 0:13:14.\n",
      "  Batch 1,880  of  5,400.    Elapsed: 0:13:32.\n",
      "  Batch 1,920  of  5,400.    Elapsed: 0:13:49.\n",
      "  Batch 1,960  of  5,400.    Elapsed: 0:14:06.\n",
      "  Batch 2,000  of  5,400.    Elapsed: 0:14:23.\n",
      "  Batch 2,040  of  5,400.    Elapsed: 0:14:41.\n",
      "  Batch 2,080  of  5,400.    Elapsed: 0:14:58.\n",
      "  Batch 2,120  of  5,400.    Elapsed: 0:15:15.\n",
      "  Batch 2,160  of  5,400.    Elapsed: 0:15:33.\n",
      "  Batch 2,200  of  5,400.    Elapsed: 0:15:50.\n",
      "  Batch 2,240  of  5,400.    Elapsed: 0:16:07.\n",
      "  Batch 2,280  of  5,400.    Elapsed: 0:16:25.\n",
      "  Batch 2,320  of  5,400.    Elapsed: 0:16:42.\n",
      "  Batch 2,360  of  5,400.    Elapsed: 0:16:59.\n",
      "  Batch 2,400  of  5,400.    Elapsed: 0:17:17.\n",
      "  Batch 2,440  of  5,400.    Elapsed: 0:17:34.\n",
      "  Batch 2,480  of  5,400.    Elapsed: 0:17:51.\n",
      "  Batch 2,520  of  5,400.    Elapsed: 0:18:09.\n",
      "  Batch 2,560  of  5,400.    Elapsed: 0:18:26.\n",
      "  Batch 2,600  of  5,400.    Elapsed: 0:18:43.\n",
      "  Batch 2,640  of  5,400.    Elapsed: 0:19:01.\n",
      "  Batch 2,680  of  5,400.    Elapsed: 0:19:18.\n",
      "  Batch 2,720  of  5,400.    Elapsed: 0:19:36.\n",
      "  Batch 2,760  of  5,400.    Elapsed: 0:19:53.\n",
      "  Batch 2,800  of  5,400.    Elapsed: 0:20:10.\n",
      "  Batch 2,840  of  5,400.    Elapsed: 0:20:28.\n",
      "  Batch 2,880  of  5,400.    Elapsed: 0:20:45.\n",
      "  Batch 2,920  of  5,400.    Elapsed: 0:21:02.\n",
      "  Batch 2,960  of  5,400.    Elapsed: 0:21:19.\n",
      "  Batch 3,000  of  5,400.    Elapsed: 0:21:37.\n",
      "  Batch 3,040  of  5,400.    Elapsed: 0:21:54.\n",
      "  Batch 3,080  of  5,400.    Elapsed: 0:22:11.\n",
      "  Batch 3,120  of  5,400.    Elapsed: 0:22:29.\n",
      "  Batch 3,160  of  5,400.    Elapsed: 0:22:46.\n",
      "  Batch 3,200  of  5,400.    Elapsed: 0:23:03.\n",
      "  Batch 3,240  of  5,400.    Elapsed: 0:23:21.\n",
      "  Batch 3,280  of  5,400.    Elapsed: 0:23:38.\n",
      "  Batch 3,320  of  5,400.    Elapsed: 0:23:55.\n",
      "  Batch 3,360  of  5,400.    Elapsed: 0:24:13.\n",
      "  Batch 3,400  of  5,400.    Elapsed: 0:24:30.\n",
      "  Batch 3,440  of  5,400.    Elapsed: 0:24:47.\n",
      "  Batch 3,480  of  5,400.    Elapsed: 0:25:05.\n",
      "  Batch 3,520  of  5,400.    Elapsed: 0:25:22.\n",
      "  Batch 3,560  of  5,400.    Elapsed: 0:25:39.\n",
      "  Batch 3,600  of  5,400.    Elapsed: 0:25:57.\n",
      "  Batch 3,640  of  5,400.    Elapsed: 0:26:14.\n",
      "  Batch 3,680  of  5,400.    Elapsed: 0:26:31.\n",
      "  Batch 3,720  of  5,400.    Elapsed: 0:26:49.\n",
      "  Batch 3,760  of  5,400.    Elapsed: 0:27:06.\n",
      "  Batch 3,800  of  5,400.    Elapsed: 0:27:23.\n",
      "  Batch 3,840  of  5,400.    Elapsed: 0:27:41.\n",
      "  Batch 3,880  of  5,400.    Elapsed: 0:27:58.\n",
      "  Batch 3,920  of  5,400.    Elapsed: 0:28:15.\n",
      "  Batch 3,960  of  5,400.    Elapsed: 0:28:33.\n",
      "  Batch 4,000  of  5,400.    Elapsed: 0:28:50.\n",
      "  Batch 4,040  of  5,400.    Elapsed: 0:29:07.\n",
      "  Batch 4,080  of  5,400.    Elapsed: 0:29:25.\n",
      "  Batch 4,120  of  5,400.    Elapsed: 0:29:42.\n",
      "  Batch 4,160  of  5,400.    Elapsed: 0:29:59.\n",
      "  Batch 4,200  of  5,400.    Elapsed: 0:30:16.\n",
      "  Batch 4,240  of  5,400.    Elapsed: 0:30:34.\n",
      "  Batch 4,280  of  5,400.    Elapsed: 0:30:51.\n",
      "  Batch 4,320  of  5,400.    Elapsed: 0:31:08.\n",
      "  Batch 4,360  of  5,400.    Elapsed: 0:31:26.\n",
      "  Batch 4,400  of  5,400.    Elapsed: 0:31:43.\n",
      "  Batch 4,440  of  5,400.    Elapsed: 0:32:00.\n",
      "  Batch 4,480  of  5,400.    Elapsed: 0:32:18.\n",
      "  Batch 4,520  of  5,400.    Elapsed: 0:32:35.\n",
      "  Batch 4,560  of  5,400.    Elapsed: 0:32:52.\n",
      "  Batch 4,600  of  5,400.    Elapsed: 0:33:10.\n",
      "  Batch 4,640  of  5,400.    Elapsed: 0:33:27.\n",
      "  Batch 4,680  of  5,400.    Elapsed: 0:33:44.\n",
      "  Batch 4,720  of  5,400.    Elapsed: 0:34:02.\n",
      "  Batch 4,760  of  5,400.    Elapsed: 0:34:19.\n",
      "  Batch 4,800  of  5,400.    Elapsed: 0:34:36.\n",
      "  Batch 4,840  of  5,400.    Elapsed: 0:34:53.\n",
      "  Batch 4,880  of  5,400.    Elapsed: 0:35:11.\n",
      "  Batch 4,920  of  5,400.    Elapsed: 0:35:28.\n",
      "  Batch 4,960  of  5,400.    Elapsed: 0:35:45.\n",
      "  Batch 5,000  of  5,400.    Elapsed: 0:36:03.\n",
      "  Batch 5,040  of  5,400.    Elapsed: 0:36:20.\n",
      "  Batch 5,080  of  5,400.    Elapsed: 0:36:37.\n",
      "  Batch 5,120  of  5,400.    Elapsed: 0:36:55.\n",
      "  Batch 5,160  of  5,400.    Elapsed: 0:37:12.\n",
      "  Batch 5,200  of  5,400.    Elapsed: 0:37:29.\n",
      "  Batch 5,240  of  5,400.    Elapsed: 0:37:47.\n",
      "  Batch 5,280  of  5,400.    Elapsed: 0:38:04.\n",
      "  Batch 5,320  of  5,400.    Elapsed: 0:38:21.\n",
      "  Batch 5,360  of  5,400.    Elapsed: 0:38:39.\n",
      "\n",
      "  Average training loss: 0.07\n",
      "  Training epcoh took: 0:38:56\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.98\n",
      "  Validation took: 0:01:19\n",
      "\n",
      "Training complete!\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_g60zz_LfPsN",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "outputId": "b2c9dac3-5241-4a78-f958-2c265b272905"
   },
   "source": [
    "t0 = time.time()\n",
    "model.eval()\n",
    "\n",
    "# Tracking variables \n",
    "eval_loss, eval_accuracy = 0, 0\n",
    "nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "# Evaluate data for one epoch\n",
    "for batch in test_dataloader:\n",
    "    \n",
    "    # Add batch to GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    \n",
    "    # Unpack the inputs from our dataloader\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    with torch.no_grad():        \n",
    "        outputs = model(b_input_ids, \n",
    "                        token_type_ids=None, \n",
    "                        attention_mask=b_input_mask)\n",
    "    \n",
    "    # Get the \"logits\" output by the model. The \"logits\" are the output\n",
    "    # values prior to applying an activation function like the softmax.\n",
    "    logits = outputs[0]\n",
    "\n",
    "    # Move logits and labels to CPU\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "    \n",
    "    # Calculate the accuracy for this batch of test sentences.\n",
    "    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "    \n",
    "    # Accumulate the total accuracy.\n",
    "    eval_accuracy += tmp_eval_accuracy\n",
    "\n",
    "    # Track the number of batches\n",
    "    nb_eval_steps += 1\n",
    "print(\"  Accuracy: {0:.4f}\".format(eval_accuracy/nb_eval_steps))\n",
    "print(\"  Test took: {:}\".format(format_time(time.time() - t0)))"
   ],
   "execution_count": 134,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.9757\n",
      "  Test took: 0:03:14\n"
     ],
     "name": "stdout"
    }
   ]
  }
 ]
}